import gradio as gr
from transformers import pipeline

# Load a LLaMA chat-optimized model
generator = pipeline(
    "text-generation",
    model="meta-llama/Llama-2-7b-chat-hf"
)

# System prompt to guide the chat
SYSTEM_PROMPT = "You are YUSR AI, a friendly and helpful chatbot. Respond concisely and naturally."

# Chat function
def chat(user_message, chat_history):
    if not user_message.strip():
        return chat_history, chat_history
    prompt = SYSTEM_PROMPT + "\nUser: " + user_message + "\nYUSR AI:"
    ai_response = generator(prompt, max_new_tokens=150)[0]["generated_text"]
    chat_history = chat_history + [(user_message, ai_response)]
    return chat_history, chat_history

# Gradio interface
with gr.Blocks(theme=gr.themes.Base()) as demo:
    gr.Markdown("<h1 style='color:#00ffae;text-align:center;'>YUSR AI ðŸ¤–</h1>")
    chatbot = gr.Chatbot()
    
    with gr.Row():
        msg = gr.Textbox(
            placeholder="Type your message here...", 
            show_label=False, 
            lines=1
        )
        send_btn = gr.Button("Send")
    
    # Connect send button and Enter key
    send_btn.click(chat, [msg, chatbot], [chatbot, chatbot])
    msg.submit(chat, [msg, chatbot], [chatbot, chatbot])

# Launch the app
demo.launch()
